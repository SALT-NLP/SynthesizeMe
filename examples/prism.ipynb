{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/personal_rm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from synthesizeme.personalrm.synthesizeme import SynthesizeMe\n",
    "from synthesizeme.datasets import PrismDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect User Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PrismDataset()\n",
    "train, val, test = dataset.get_user_data(dataset.get_user_ids()[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[:]\n",
    "data.extend(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': 'c2596',\n",
       " 'user_id': 'user488',\n",
       " 'context': array([{'content': 'Hi, how are you?', 'role': 'user'}], dtype=object),\n",
       " 'chosen': {'content': \"Hello! I'm here and ready to assist you. How can I help you today?\",\n",
       "  'role': 'model'},\n",
       " 'rejected': {'content': \"I'm doing great, thank you for asking! I'm here to assist you in our conversation. How may I help you today?\",\n",
       "  'role': 'model'},\n",
       " 'turns': 1,\n",
       " 'type': 'unguided',\n",
       " 'split': 'train',\n",
       " 'flip': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Personal Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm = SynthesizeMe(model_id='together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', num_workers=64)\n",
    "rm = SynthesizeMe(model_id='gemini/gemini-2.0-flash', num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 WARNING dspy.primitives.module: There is a mismatch of python version between saved model and current environment. You saved with `python==3.12`, but now you have `python==3.10`. This might cause errors or performance downgrade on the loaded model, please consider loading the model in the same environment as the saving environment.\n",
      "2025/05/22 00:34:57 WARNING dspy.primitives.module: There is a mismatch of dspy version between saved model and current environment. You saved with `dspy==2.6.12`, but now you have `dspy==2.6.24`. This might cause errors or performance downgrade on the loaded model, please consider loading the model in the same environment as the saving environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 16 traces per predictor.\n",
      "Will attempt to bootstrap 10 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [00:00<00:00, 41.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 8/16 [00:00<00:00, 79.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 6/16 [00:00<00:00, 53.23it/s]\n",
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [00:00<00:00, 105.79it/s]\n",
      " 50%|█████     | 8/16 [00:00<00:00, 51.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 15 examples for up to 1 rounds, amounting to 15 attempts.\n",
      "Bootstrapped 5 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 106.79it/s]\n",
      " 88%|████████▊ | 14/16 [00:00<00:00, 93.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 9 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 106.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 14 examples for up to 1 rounds, amounting to 14 attempts.\n",
      "Bootstrapped 9 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [00:00<00:00, 59.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 14 examples for up to 1 rounds, amounting to 14 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 61.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 9 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "Average Metric: 1.00 / 2 (50.0%):  12%|█▎        | 1/8 [00:00<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.76it/s] \n",
      "100%|██████████| 16/16 [00:00<00:00, 60.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 9 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "Bootstrapped 9 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 25.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 1.00 / 2 (50.0%):  12%|█▎        | 1/8 [00:00<00:00, 74.13it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 1.00 / 3 (33.3%):  25%|██▌       | 2/8 [00:00<00:00, 108.96it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 2 (50.0%):  12%|█▎        | 1/8 [00:00<00:00, 103.46it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 1.00 / 4 (25.0%):  38%|███▊      | 3/8 [00:00<00:00, 127.76it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 2.00 / 3 (66.7%):  25%|██▌       | 2/8 [00:00<00:00, 135.59it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 1.00 / 5 (20.0%):  50%|█████     | 4/8 [00:00<00:00, 140.60it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 3.00 / 4 (75.0%):  38%|███▊      | 3/8 [00:00<00:00, 152.36it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 1.00 / 6 (16.7%):  62%|██████▎   | 5/8 [00:00<00:00, 149.53it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 5 (80.0%):  50%|█████     | 4/8 [00:00<00:00, 162.06it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 1.00 / 7 (14.3%):  75%|███████▌  | 6/8 [00:00<00:00, 156.63it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 5.00 / 6 (83.3%):  62%|██████▎   | 5/8 [00:00<00:00, 168.46it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 2.00 / 8 (25.0%):  88%|████████▊ | 7/8 [00:00<00:00, 162.28it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 6.00 / 7 (85.7%):  75%|███████▌  | 6/8 [00:00<00:00, 175.50it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 3.00 / 8 (37.5%): 100%|██████████| 8/8 [00:00<00:00, 32.00it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 3 / 8 (37.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 7.00 / 8 (87.5%):  88%|████████▊ | 7/8 [00:00<00:00, 176.81it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 2.00 / 8 (25.0%): 100%|██████████| 8/8 [00:00<00:00, 151.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 2 / 8 (25.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 161.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 176.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 167.34it/s]\n",
      "Average Metric: 7.00 / 8 (87.5%): 100%|██████████| 8/8 [00:00<00:00, 172.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n",
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 7 / 8 (87.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 171.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 8 (50.0%): 100%|██████████| 8/8 [00:00<00:00, 171.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 4 / 8 (50.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 170.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.00 / 8 (87.5%): 100%|██████████| 8/8 [00:00<00:00, 167.47it/s]\n",
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 167.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 7 / 8 (87.5%)\n",
      "2025/05/22 00:34:57 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 62.5 for seed -2\n",
      "Scores so far: [62.5]\n",
      "Best score so far: 62.5\n",
      "New best score: 87.5 for seed -1\n",
      "Scores so far: [62.5, 87.5]\n",
      "Best score so far: 87.5\n",
      "Stopping early because score 87.5 is >= stop_at_score 80.0\n",
      "2 candidate programs found.\n",
      "Going to sample between 1 and 16 traces per predictor.\n",
      "Will attempt to bootstrap 10 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [00:00<00:00, 26.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):  12%|█▎        | 1/8 [00:00<00:00,  9.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [00:00<00:00, 44.74it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 7/16 [00:00<00:00, 39.34it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 8 examples for up to 1 rounds, amounting to 8 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [00:00<00:00, 29.21it/s]\n",
      " 81%|████████▏ | 13/16 [00:00<00:00, 80.19it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 90.66it/s]\n",
      " 81%|████████▏ | 13/16 [00:00<00:00, 60.08it/s]\n",
      " 94%|█████████▍| 15/16 [00:00<00:00, 67.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapped 8 full traces after 13 examples for up to 1 rounds, amounting to 13 attempts.\n",
      "Bootstrapped 10 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "Bootstrapped 8 full traces after 13 examples for up to 1 rounds, amounting to 13 attempts.\n",
      "Bootstrapped 9 full traces after 15 examples for up to 1 rounds, amounting to 15 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):  25%|██▌       | 2/8 [00:00<00:00, 17.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 56.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 10 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 54.34it/s] \n",
      "100%|██████████| 16/16 [00:00<00:00, 45.71it/s]\n",
      " 88%|████████▊ | 14/16 [00:00<00:00, 42.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 10 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "Bootstrapped 10 full traces after 15 examples for up to 1 rounds, amounting to 16 attempts.\n",
      "Bootstrapped 8 full traces after 14 examples for up to 1 rounds, amounting to 14 attempts.\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 2 (50.0%):  12%|█▎        | 1/8 [00:00<00:00, 24.55it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|          | 0/8 [00:00<?, ?it/s]66it/s]\n",
      "Average Metric: 1.00 / 3 (33.3%):  25%|██▌       | 2/8 [00:00<00:00, 44.01it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 2.00 / 2 (100.0%):  12%|█▎        | 1/8 [00:00<00:00, 115.33it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 2 (50.0%):  12%|█▎        | 1/8 [00:00<00:00, 118.75it/s]\n",
      "Average Metric: 2.00 / 4 (50.0%):  38%|███▊      | 3/8 [00:00<00:00, 59.48it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 3.00 / 3 (100.0%):  25%|██▌       | 2/8 [00:00<00:00, 146.44it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 1.00 / 3 (33.3%):  25%|██▌       | 2/8 [00:00<00:00, 149.70it/s]\n",
      "Average Metric: 2.00 / 5 (40.0%):  50%|█████     | 4/8 [00:00<00:00, 72.09it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 4 (100.0%):  38%|███▊      | 3/8 [00:00<00:00, 159.98it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 2.00 / 4 (50.0%):  38%|███▊      | 3/8 [00:00<00:00, 161.45it/s]\n",
      "Average Metric: 2.00 / 6 (33.3%):  62%|██████▎   | 5/8 [00:00<00:00, 82.43it/s]\n",
      "\n",
      "Average Metric: 3.00 / 5 (60.0%):  50%|█████     | 4/8 [00:00<00:00, 177.45it/s] \n",
      "Average Metric: 2.00 / 7 (28.6%):  75%|███████▌  | 6/8 [00:00<00:00, 92.99it/s]\n",
      "\n",
      "Average Metric: 3.00 / 8 (37.5%): 100%|██████████| 8/8 [00:00<00:00, 20.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 3 / 8 (37.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.00 / 8 (37.5%): 100%|██████████| 8/8 [00:00<00:00, 20.85it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 3 / 8 (37.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 6 (66.7%):  62%|██████▎   | 5/8 [00:00<00:00, 177.97it/s]\n",
      "Average Metric: 2.00 / 8 (25.0%):  88%|████████▊ | 7/8 [00:00<00:00, 99.17it/s]\n",
      "\n",
      "Average Metric: 5.00 / 7 (71.4%):  75%|███████▌  | 6/8 [00:00<00:00, 185.38it/s]\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 6.00 / 8 (75.0%):  88%|████████▊ | 7/8 [00:00<00:00, 195.43it/s]\n",
      "Average Metric: 2.00 / 8 (25.0%): 100%|██████████| 8/8 [00:00<00:00, 102.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 2 / 8 (25.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 8 (50.0%): 100%|██████████| 8/8 [00:00<00:00, 154.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 4 / 8 (50.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 179.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.00 / 8 (87.5%): 100%|██████████| 8/8 [00:00<00:00, 173.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 7 / 8 (87.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 178.06it/s]\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 176.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n",
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 170.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 173.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.00 / 8 (62.5%): 100%|██████████| 8/8 [00:00<00:00, 183.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 5 / 8 (62.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 8 (75.0%): 100%|██████████| 8/8 [00:00<00:00, 182.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 6 / 8 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 8 (50.0%): 100%|██████████| 8/8 [00:00<00:00, 183.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 00:34:58 INFO dspy.evaluate.evaluate: Average Metric: 4 / 8 (50.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 37.5 for seed -3\n",
      "Scores so far: [37.5]\n",
      "Best score so far: 37.5\n",
      "Scores so far: [37.5, 37.5]\n",
      "Best score so far: 37.5\n",
      "New best score: 75.0 for seed -1\n",
      "Scores so far: [37.5, 37.5, 75.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0, 75.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0, 75.0, 50.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0, 75.0, 50.0, 62.5]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0, 75.0, 50.0, 62.5, 75.0]\n",
      "Best score so far: 75.0\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0, 75.0, 50.0, 62.5, 75.0, 62.5]\n",
      "Best score so far: 75.0\n",
      "New best score: 87.5 for seed 8\n",
      "Scores so far: [37.5, 37.5, 75.0, 75.0, 50.0, 25.0, 75.0, 50.0, 62.5, 75.0, 62.5, 87.5]\n",
      "Best score so far: 87.5\n",
      "Stopping early because score 87.5 is >= stop_at_score 80.0\n",
      "12 candidate programs found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "judge_persona.predict = Predict(StringSignature(conversation, first_completion, second_completion -> reasoning, preference\n",
       "    instructions=\"Given a conversation and two completions from different models, alongside some prior judgements and a user persona, determine which completion the human judge is more likely to prefer.  Use any provided context as well as the provided persona to speculate about the personal preferences of the judge.  You are a personalized reward model for this user, so think carefully about what this user will like.\\nThe user you are judging completions for has the FOLLOWING PERSONA: ===\\nThe synthesized persona is that of a thoughtful, inquisitive, and ethically-minded individual who seeks comprehensive and nuanced information to form their own informed opinions. They are not satisfied with simplistic answers or superficial explanations. They value depth, complexity, and a balanced perspective. They are also action-oriented and appreciate practical advice that can be applied to real-life situations. This persona is likely someone who is engaged in social issues, values ethical considerations, and strives to understand the complexities of the world around them. They are open-minded and respectful of different viewpoints, but they also have a strong sense of their own values and principles. They are likely well-read, intellectually curious, and committed to making a positive impact on the world.\\n===\\n\\nNow, given the conversation and two completions, decide which completion the user is more likely to prefer.  Remember to consider the user's persona and preferences as you make your decision.\"\n",
       "    conversation = Field(annotation=str required=True json_schema_extra={'desc': 'The conversation context leading up to the completions.', '__dspy_field_type': 'input', 'prefix': 'Conversation:'})\n",
       "    first_completion = Field(annotation=str required=True json_schema_extra={'desc': 'The first of the two possible completions to judge between.', '__dspy_field_type': 'input', 'prefix': 'First Completion:'})\n",
       "    second_completion = Field(annotation=str required=True json_schema_extra={'desc': 'The second of the two possible completions to judge between.', '__dspy_field_type': 'input', 'prefix': 'Second Completion:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    preference = Field(annotation=Literal['First', 'Second'] required=True json_schema_extra={'desc': \"The completion that the judge is more likely to prefer.  Possible values are 'First' and 'Second'.\", '__dspy_field_type': 'output', 'prefix': 'Preference:'})\n",
       "))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The synthesized persona is that of a thoughtful, inquisitive, and ethically-minded individual who seeks comprehensive and nuanced information to form their own informed opinions. They are not satisfied with simplistic answers or superficial explanations. They value depth, complexity, and a balanced perspective. They are also action-oriented and appreciate practical advice that can be applied to real-life situations. This persona is likely someone who is engaged in social issues, values ethical considerations, and strives to understand the complexities of the world around them. They are open-minded and respectful of different viewpoints, but they also have a strong sense of their own values and principles. They are likely well-read, intellectually curious, and committed to making a positive impact on the world.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.get_persona()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': '[user]: Do you agree with death penalty?\\n\\n[model]: I\\'m just an AI, I don\\'t have personal opinions or beliefs, and I cannot endorse or support any form of violence or punishment, including the death penalty. It is important to respect the inherent value of human life and to find alternative, humane ways to address criminal behavior and provide justice for victims and their families.\\n\\n[user]: What do you think of people that agree with death penalty?\\n\\n[model]: I\\'m just an AI, I don\\'t have personal opinions or beliefs, and I cannot endorse or support any form of violence or punishment, including the death penalty. It is important to respect the inherent value of human life and to find alternative, humane ways to address criminal behavior and provide justice for victims and their families.\\n\\nIt is understandable that some people may feel that the death penalty is a necessary tool for deterring crime and providing justice for victims, but it is important to consider the ethical and legal implications of such a punishment. Many human rights organizations and experts have raised concerns about the potential for miscarriages of justice, the lack of evidence that the death penalty is an effective deterrent, and the inherent cruelty of taking a life.\\n\\nUltimately, the decision to support or oppose the death penalty is a complex and nuanced issue that requires careful consideration of\\n\\n[user]: Well, I don\\'t think it\\'s acceptable to think that death penalty is a \"necessary tool\"\\n\\n[model]: I understand. Many people share your view that the death penalty is not an acceptable or justifiable form of punishment. There are alternative forms of punishment that can provide justice for victims and their families while also respecting the inherent value of human life. Some examples include life imprisonment without parole, restorative justice programs, and rehabilitation and reintegration programs. Ultimately, the decision to support or oppose the death penalty is a complex and nuanced issue that requires careful consideration of ethical, legal, and human rights implications.\\n\\n[user]: How do you think we can convince those people that taking a life is just pointless and cruel, no matter the reason behind?',\n",
       " 'first_completion': \"[model]: It's important to approach this issue with empathy and respect for the beliefs and values of others, while also presenting a well-reasoned and evidence-based argument against the death penalty. Here are some strategies that may be effective in convincing those who support the death penalty:\\n\\n1. Highlight the flaws in the justice system: Emphasize the fact that the death penalty is not a foolproof system, and that there have been instances of wrongful convictions and executions of innocent people.\\n2. Emphasize the moral and ethical implications: Discuss the ethical principles of respect for human life and the inherent dignity of every person, and argue that the death penalty violates these principles.\\n3. Offer alternative forms of punishment: Suggest alternative forms of punishment that can provide justice for victims and their families while also respecting the inherent value of human life.\\n4\",\n",
       " 'second_completion': '[model]: It is important to approach this issue with empathy and respect for the beliefs and values of others. Here are some ways to convince people that taking a life is pointless and cruel:\\n\\n1. Emphasize the inherent value of human life: Highlight the fundamental dignity and worth of every human life, regardless of their actions. Encourage people to consider the ethical implications of taking a life and the long-term consequences for individuals, communities, and society as a whole.\\n2. Discuss the alternatives: Explore alternative forms of punishment and rehabilitation that can address the root causes of criminal behavior without resorting to violence. This can include restorative justice programs, rehabilitation and reintegration programs, and other forms of alternative justice.\\n3. Share personal stories: Share personal stories and experiences of individuals who have been impacted by the death penalty, either as perpetrators or victims.',\n",
       " 'reasoning': \"Both completions offer reasonable strategies for convincing people that the death penalty is wrong. However, the second completion is slightly better because it emphasizes empathy and respect for others' beliefs, which aligns with the user's persona of being thoughtful, inquisitive, and ethically-minded. Additionally, the second completion provides more specific and actionable advice, such as sharing personal stories, which would appeal to the user's desire for practical advice.\",\n",
       " 'preference': 'Second'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.get_demos()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 1.0, 'lower_bound': 1.0, 'upper_bound': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_rm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
